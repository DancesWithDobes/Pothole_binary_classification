{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "VBzeLWl6r0Hf"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.models import resnet50\n",
        "import torchvision.datasets as datasets\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, precision_recall_curve, average_precision_score, roc_curve, roc_auc_score\n",
        "\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.models import resnet50\n",
        "import torchvision.datasets as datasets\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, precision_recall_curve, average_precision_score, roc_curve, roc_auc_score\n",
        "import itertools\n",
        "import itertools"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Set the directory paths\n",
        "train_dir = '/content/drive/MyDrive/Pothole data/organized_data/train'  # Update with your train directory path\n",
        "val_dir = '/content/drive/MyDrive/Pothole data/organized_data/val'  # Update with your validation directory path\n",
        "test_dir = '/content/drive/MyDrive/Pothole data/organized_data/test'  # Update with your test directory path\n",
        "model_dir = '/content/drive/MyDrive/Pothole data/models from updated neural network'  # Update with your model save directory path"
      ],
      "metadata": {
        "id": "oJEcmpWOsOet"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PotholeClassifier:\n",
        "    def __init__(self, train_dir, val_dir, test_dir, model_dir, num_epochs=10, batch_size=32, learning_rate=0.001, patience=3):\n",
        "        self.train_dir = train_dir\n",
        "        self.val_dir = val_dir\n",
        "        self.test_dir = test_dir\n",
        "        self.model_dir = model_dir\n",
        "        self.num_epochs = num_epochs\n",
        "        self.batch_size = batch_size\n",
        "        self.learning_rate = learning_rate\n",
        "        self.patience = patience\n",
        "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.Resize((224, 224)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "        ])\n",
        "\n",
        "        self.train_dataset = datasets.ImageFolder(self.train_dir, transform=self.transform)\n",
        "        self.val_dataset = datasets.ImageFolder(self.val_dir, transform=self.transform)\n",
        "        self.test_dataset = datasets.ImageFolder(self.test_dir, transform=self.transform)\n",
        "\n",
        "        self.train_loader = DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=True)\n",
        "        self.val_loader = DataLoader(self.val_dataset, batch_size=self.batch_size, shuffle=False)\n",
        "        self.test_loader = DataLoader(self.test_dataset, batch_size=self.batch_size, shuffle=False)\n",
        "\n",
        "        self.model = self._initialize_model()\n",
        "        self.criterion = nn.CrossEntropyLoss()\n",
        "        self.optimizer = optim.Adam(self.model.parameters(), lr=self.learning_rate)\n",
        "        self.best_val_loss = float('inf')\n",
        "        self.epochs_without_improvement = 0\n",
        "        self.val_losses = []  # List to store validation losses\n",
        "\n",
        "    def _initialize_model(self):\n",
        "        model = resnet50(pretrained=True)\n",
        "\n",
        "        for param in model.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "        num_features = model.fc.in_features\n",
        "        model.fc = nn.Linear(num_features, 2)  # Assuming 2 classes: pothole and normal\n",
        "\n",
        "        model = model.to(self.device)\n",
        "\n",
        "        return model\n",
        "\n",
        "    def train(self):\n",
        "        for epoch in range(self.num_epochs):\n",
        "            self.model.train()\n",
        "            for images, labels in self.train_loader:\n",
        "                images = images.to(self.device)\n",
        "                labels = labels.to(self.device)\n",
        "\n",
        "                self.optimizer.zero_grad()\n",
        "                outputs = self.model(images)\n",
        "                loss = self.criterion(outputs, labels)\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "\n",
        "            # Evaluate the model on the validation set\n",
        "            self.model.eval()\n",
        "            val_loss = 0\n",
        "            correct = 0\n",
        "            total = 0\n",
        "            with torch.no_grad():\n",
        "                for images, labels in self.val_loader:\n",
        "                    images = images.to(self.device)\n",
        "                    labels = labels.to(self.device)\n",
        "\n",
        "                    outputs = self.model(images)\n",
        "                    _, predicted = torch.max(outputs.data, 1)\n",
        "                    total += labels.size(0)\n",
        "                    correct += (predicted == labels).sum().item()\n",
        "                    val_loss += self.criterion(outputs, labels).item()\n",
        "\n",
        "            # Calculate average validation loss and accuracy\n",
        "            val_loss /= len(self.val_loader)\n",
        "            accuracy = 100 * correct / total\n",
        "\n",
        "            # Append validation loss to the list\n",
        "            self.val_losses.append(val_loss)\n",
        "\n",
        "            # Check if validation loss has improved\n",
        "            if val_loss < self.best_val_loss:\n",
        "                self.best_val_loss = val_loss\n",
        "                self.epochs_without_improvement = 0\n",
        "                # Save the model if it's the best so far\n",
        "                self.save_model('best_model.pth')\n",
        "            else:\n",
        "                self.epochs_without_improvement += 1\n",
        "\n",
        "            # Print training progress and validation metrics\n",
        "            print(f'Epoch {epoch+1}/{self.num_epochs}, Loss: {loss.item():.4f}, '\n",
        "                  f'Validation Loss: {val_loss:.4f}, Validation Accuracy: {accuracy:.2f}%')\n",
        "\n",
        "            # Check if training should be stopped based on patience value\n",
        "            if self.epochs_without_improvement >= self.patience:\n",
        "                print(f'Early stopping. No improvement in validation loss for {self.patience} epochs.')\n",
        "                break\n",
        "\n",
        "        # Plot and save the validation loss graph\n",
        "        self.plot_validation_loss()\n",
        "\n",
        "        # Perform testing and save metrics\n",
        "        self.test()\n",
        "\n",
        "    def plot_validation_loss(self):\n",
        "        plt.plot(self.val_losses, label='Validation Loss')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.title('Validation Loss over Epochs')\n",
        "        plt.legend()\n",
        "        save_path = os.path.join(self.model_dir, 'validation_loss_graph.png')\n",
        "        plt.savefig(save_path)\n",
        "        plt.close()\n",
        "\n",
        "    def test(self):\n",
        "        self.model.eval()\n",
        "        test_loss = 0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        predictions = []\n",
        "        true_labels = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for images, labels in self.test_loader:\n",
        "                images = images.to(self.device)\n",
        "                labels = labels.to(self.device)\n",
        "\n",
        "                outputs = self.model(images)\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "                test_loss += self.criterion(outputs, labels).item()\n",
        "\n",
        "                predictions.extend(predicted.cpu().numpy())\n",
        "                true_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "        # Calculate average test loss and accuracy\n",
        "        test_loss /= len(self.test_loader)\n",
        "        accuracy = 100 * correct / total\n",
        "\n",
        "        # Compute other metrics\n",
        "        confusion = confusion_matrix(true_labels, predictions)\n",
        "        specificity = self.calculate_specificity(confusion)\n",
        "        precision, recall, thresholds = precision_recall_curve(true_labels, predictions)\n",
        "        average_precision = average_precision_score(true_labels, predictions)\n",
        "        fpr, tpr, roc_thresholds = roc_curve(true_labels, predictions)\n",
        "        auc_roc = roc_auc_score(true_labels, predictions)\n",
        "\n",
        "        # Save metrics\n",
        "        self.save_metric('accuracy.txt', accuracy)\n",
        "        self.save_metric('specificity.txt', specificity)\n",
        "        self.save_metric('average_precision.txt', average_precision)\n",
        "        self.save_metric('auc_roc.txt', auc_roc)\n",
        "        self.save_confusion_matrix(confusion)\n",
        "        self.plot_precision_recall_curve(precision, recall)\n",
        "        self.plot_roc_curve(fpr, tpr)\n",
        "\n",
        "        # Print test metrics\n",
        "        print(f'Test Loss: {test_loss:.4f}, Test Accuracy: {accuracy:.2f}%')\n",
        "\n",
        "    def save_metric(self, filename, metric_value):\n",
        "        save_path = os.path.join(self.model_dir, filename)\n",
        "        with open(save_path, 'w') as f:\n",
        "            f.write(str(metric_value))\n",
        "\n",
        "    def save_confusion_matrix(self, cm):\n",
        "        plt.figure()\n",
        "        classes = ['Normal', 'Pothole']\n",
        "        plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
        "        plt.title('Confusion Matrix')\n",
        "        plt.colorbar()\n",
        "        tick_marks = np.arange(len(classes))\n",
        "        plt.xticks(tick_marks, classes)\n",
        "        plt.yticks(tick_marks, classes)\n",
        "\n",
        "        thresh = cm.max() / 2.\n",
        "        for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "            plt.text(j, i, cm[i, j], horizontalalignment='center', color='white' if cm[i, j] > thresh else 'black')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.xlabel('Predicted Label')\n",
        "        plt.ylabel('True Label')\n",
        "        save_path = os.path.join(self.model_dir, 'confusion_matrix.png')\n",
        "        plt.savefig(save_path)\n",
        "        plt.close()\n",
        "\n",
        "    def plot_precision_recall_curve(self, precision, recall):\n",
        "        plt.plot(recall, precision, marker='.')\n",
        "        plt.xlabel('Recall')\n",
        "        plt.ylabel('Precision')\n",
        "        plt.title('Precision-Recall Curve')\n",
        "        save_path = os.path.join(self.model_dir, 'precision_recall_curve.png')\n",
        "        plt.savefig(save_path)\n",
        "        plt.close()\n",
        "\n",
        "    def plot_roc_curve(self, fpr, tpr):\n",
        "        plt.plot(fpr, tpr, marker='.')\n",
        "        plt.xlabel('False Positive Rate')\n",
        "        plt.ylabel('True Positive Rate')\n",
        "        plt.title('ROC Curve')\n",
        "        save_path = os.path.join(self.model_dir, 'roc_curve.png')\n",
        "        plt.savefig(save_path)\n",
        "        plt.close()\n",
        "\n",
        "    def calculate_specificity(self, confusion):\n",
        "        tn = confusion[0, 0]\n",
        "        fp = confusion[0, 1]\n",
        "        specificity = tn / (tn + fp)\n",
        "        return specificity\n",
        "\n",
        "\n",
        "    def save_model(self, filepath):\n",
        "      save_path = os.path.join(self.model_dir, filepath)\n",
        "      torch.save(self.model.state_dict(), save_path)\n",
        "      print(f\"Model saved at '{save_path}'\")\n"
      ],
      "metadata": {
        "id": "u5ZrlWjDsWqA"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an instance of the PotholeClassifier\n",
        "classifier = PotholeClassifier(train_dir, val_dir, test_dir, model_dir)\n",
        "\n",
        "# Train the classifier\n",
        "classifier.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ywuSENFvsd0P",
        "outputId": "a0e95edd-d268-41d3-99f6-9da9d4ce4cb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
            "100%|██████████| 97.8M/97.8M [00:04<00:00, 24.6MB/s]\n"
          ]
        }
      ]
    }
  ]
}